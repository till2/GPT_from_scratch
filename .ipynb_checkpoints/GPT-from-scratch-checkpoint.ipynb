{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6f554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Hello worldo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1. done.\n",
    "# 2. use multiple blocks sequentially ==> done.\n",
    "# 3. rename to transformer ==> done. (TransformerLanguageModel)\n",
    "# 4. add tqdm ==> done.\n",
    "# 5. use full dataset ==> done.\n",
    "# 6. make model bigger ==> done.\n",
    "# 7. find out good batch size (for full gpu) ==> done.\n",
    "# 8. find training time -> steps ==> done. (8.30min per 1k steps)\n",
    "# 9. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa94449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(3654)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352e283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c6932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# report the parameters | and loss with 5k training steps:\n",
    "\n",
    "# --- small 10k dataset ---\n",
    "# bigram model: 3844 ==> loss to 2.5\n",
    "# with one multihead attention (5 heads): 53262 ==> loss to 0.35\n",
    "# with one multihead attention (5 heads) and residual connection: 53262 ==> loss to 0.30\n",
    "# with one full block: 134162 ==> loss to 0.24\n",
    "# with 5 blocks: 617762 ==> loss to 0.12\n",
    "\n",
    "# --- large dataset --- \n",
    "# bigger model: 5015318 (5M) ==> loss to 0.0116"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e1971",
   "metadata": {},
   "source": [
    "### Get text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e97ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text_corpus.txt\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()# [:10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c86b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea75fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f90281",
   "metadata": {},
   "source": [
    "### Encode the characters to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c27f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder and decoder dicts\n",
    "\n",
    "char_int_mapping = dict()\n",
    "int_char_mapping = dict()\n",
    "\n",
    "for i, c in enumerate(sorted(set(text))):\n",
    "    char_int_mapping[c] = i\n",
    "    int_char_mapping[i] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f799812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples\n",
    "print(char_int_mapping[\"g\"])\n",
    "print(int_char_mapping[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56852e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(string: str) -> List[int]:\n",
    "    int_list = [char_int_mapping[char] for char in string]\n",
    "    return int_list\n",
    "\n",
    "def decode(int_list: List[int]) -> str:\n",
    "    string = [int_char_mapping[num] for num in int_list]\n",
    "    return \"\".join(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77fe53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples\n",
    "print(encode(\"hellooo\"))\n",
    "print(decode([43, 40, 47, 47, 50, 50, 50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931bc151",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b0040",
   "metadata": {},
   "source": [
    "### Make it a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7650c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222f0765",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49865796",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(0.9*len(data))\n",
    "train_data = data[:N]\n",
    "test_data = data[N:]\n",
    "\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f353e",
   "metadata": {},
   "source": [
    "### Create minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8 # block_size is the maximum context length (input textblock size)\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[:block_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032acc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split: torch.tensor):\n",
    "    offsets = np.random.randint(0, len(split) - block_size, size=batch_size)\n",
    "    x = torch.stack([split[i:i+block_size] for i in offsets]).to(device)\n",
    "    y = torch.stack([split[i+1:i+block_size+1] for i in offsets]).to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b37b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = get_batch(train_data)\n",
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc59eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1859006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode(xb[3].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf66d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(batch_size):\n",
    "    print(f\"----- BATCH {b} -----\")\n",
    "    \n",
    "    for t in range(block_size):\n",
    "        context = xb[b][:t+1]\n",
    "        target = yb[b][t]\n",
    "        print(f\"context: {decode(context.tolist())} -> target: {decode([int(target)])}\")\n",
    "    print()\n",
    "        \n",
    "    for t in range(block_size):\n",
    "        context = xb[b][:t+1]\n",
    "        target = yb[b][t]\n",
    "        print(f\"context: {context.tolist()} -> target: {int(target)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e228c",
   "metadata": {},
   "source": [
    "### Create a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83559181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, context, targets):\n",
    "        logits = self.token_embedding_table(context) # (Batch, Time, Channels) ==> [4, 8, 62]\n",
    "\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T,C) # [32,64]\n",
    "        targets = targets.view(B*T) # [32]\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, context, max_new_tokens):\n",
    "        \n",
    "        # context: (Batch, Time) ==> [4, 8]\n",
    "        # -> extend context in Time dimension for max_new_tokens\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            \n",
    "            # get prediction\n",
    "            logits, loss = self(xb, yb)\n",
    "            \n",
    "            # get logits for the last character \n",
    "            # (because we only need the last char to predict with our bigram model)\n",
    "            logits = logits.view(batch_size,-1,vocab_size) # (B,T,C)\n",
    "            logits = logits[:, -1, :] # (B,C) for only the last character\n",
    "            \n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            next_token = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            \n",
    "            # append next token to the sequence\n",
    "            context = torch.cat((context, next_token), dim=1) # (B,T+1)\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def generate_to_text(self, context, max_new_tokens):\n",
    "        context = self.generate(context, max_new_tokens)\n",
    "        return decode(context[0].tolist())\n",
    "\n",
    "model = BigramLanguageModel(vocab_size).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48112030",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa35b9e",
   "metadata": {},
   "source": [
    "### Train the simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ccb16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "losses = []\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for step in range(5_000):\n",
    "    \n",
    "    # get a batch\n",
    "    xb, yb = get_batch(train_data)\n",
    "    \n",
    "    # predict and get loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9985f728",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b39d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "zero_context = torch.zeros((batch_size,1)).to(device)\n",
    "model.generate_to_text(zero_context, max_new_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08472cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9344c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca4650f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84918d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a09dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e37b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d734efb2",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a1db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.rand(5,1)\n",
    "K = torch.rand(5,1)\n",
    "V = torch.rand(5,1)\n",
    "Q,K,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ff056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(Q,K,V):\n",
    "    \"\"\" \n",
    "    Applies masked scaled dot-product attention\n",
    "    between vectors of queries Q, keys K and values V. \n",
    "    \"\"\"\n",
    "    d_k = torch.tensor(Q.shape[0])\n",
    "    W = (Q @ K.T) / torch.sqrt(d_k)\n",
    "    \n",
    "    # mask out forbidden connections\n",
    "    tril = torch.tril(torch.ones((d_k, d_k)))\n",
    "    W = W.masked_fill(tril==0, float(\"-inf\"))\n",
    "    \n",
    "    W = F.softmax(W, dim=1)\n",
    "    \n",
    "    return W @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention(Q,K,V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aa6afc",
   "metadata": {},
   "source": [
    "### Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2974bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention(Q,K,V):\n",
    "    d_k = torch.tensor(Q.shape[0])\n",
    "    d_model = 8 # project in to this space\n",
    "    N_heads = 2\n",
    "    \n",
    "    # linear layers\n",
    "    projections = {\n",
    "        x: {\n",
    "            h: nn.Linear(d_k, d_model, bias=False) for h in range(N_heads)\n",
    "        } for x in [\"Q\", \"K\", \"V\"]\n",
    "    }\n",
    "    \n",
    "    # layer to combine the concatenated attention-block output vectors\n",
    "    top_layer = nn.Linear(N_heads * d_model, d_k, bias=False)\n",
    "    \n",
    "    # forward pass\n",
    "    result = torch.zeros(N_heads, d_model, 1)\n",
    "\n",
    "    for h in range(N_heads):\n",
    "        result[h] = attention(\n",
    "            projections[\"Q\"][h](Q.T).T,\n",
    "            projections[\"K\"][h](K.T).T,\n",
    "            projections[\"V\"][h](V.T).T\n",
    "        )\n",
    "    \n",
    "    concat_attn_out = result.view(1, N_heads * d_model)\n",
    "    return top_layer(concat_attn_out).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02622e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head_attention(Q,K,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1dcadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_k = torch.tensor(Q.shape[0])\n",
    "d_model = 8 # project in to this space\n",
    "N_heads = 2\n",
    "\n",
    "projections = {\n",
    "    x: {\n",
    "        h: nn.Linear(d_k, d_model, bias=False) for h in range(N_heads)\n",
    "    } for x in [\"Q\", \"K\", \"V\"]\n",
    "}\n",
    "\n",
    "projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887ed9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "projections[\"Q\"][0](Q.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34155394",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention(Q,K,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.zeros(N_heads, d_model, 1)\n",
    "\n",
    "for h in range(N_heads):\n",
    "    result[h] = attention(\n",
    "        projections[\"Q\"][h](Q.T).T,\n",
    "        projections[\"K\"][h](K.T).T,\n",
    "        projections[\"V\"][h](V.T).T\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acea947",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_attn_out = result.view(1, N_heads * d_model)\n",
    "concat_attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b814be6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283f5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_layer = nn.Linear(N_heads * d_model, d_k, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18372fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_layer(concat_attn_out).T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6cb416",
   "metadata": {},
   "source": [
    "### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8850598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "tril = torch.tril(torch.ones((T,T)))\n",
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.rand((T,T)) # there will be real data here\n",
    "\n",
    "# mask out forbidden connections\n",
    "W = W.masked_fill(tril==0, float(\"-inf\")) # set everywhere where tril is 0 to -inf (upper right)\n",
    "\n",
    "W = F.softmax(W, dim=-1)\n",
    "plt.imshow(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75c3ee1",
   "metadata": {},
   "source": [
    "### Positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b414c3",
   "metadata": {},
   "source": [
    "- learned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c4b72",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d540ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "training_steps = 5000\n",
    "embed_dims = 128 # is equivalent to d_model\n",
    "block_size = 256\n",
    "batch_size = 128\n",
    "n_heads = 8\n",
    "head_size = embed_dims // n_heads\n",
    "n_layers = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccd97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionHead(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.proj_q = nn.Linear(embed_dims, head_size, bias=False)\n",
    "        self.proj_k = nn.Linear(embed_dims, head_size, bias=False)\n",
    "        self.proj_v = nn.Linear(embed_dims, head_size, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" \n",
    "        Applies masked scaled dot-product attention\n",
    "        between vectors of queries Q, keys K and values V. \n",
    "        \"\"\"\n",
    "        B,T,C = x.shape\n",
    "        \n",
    "        Q = self.proj_q(x)\n",
    "        K = self.proj_k(x)\n",
    "        V = self.proj_v(x)\n",
    "\n",
    "        W = (Q @ K.transpose(-1,-2)) # (B, T, C) @ (B, C, T) ==> (B,T,T)\n",
    "        W /= torch.sqrt(torch.tensor(head_size))\n",
    "        \n",
    "        # mask out forbidden connections\n",
    "        tril = torch.tril(torch.ones((block_size, block_size), device=device))\n",
    "        W = W.masked_fill(tril[:T, :T]==0, float(\"-inf\")) # make smaller so it fits if context < block_size\n",
    "        W = F.softmax(W, dim=1)\n",
    "        out = W @ V\n",
    "        return out # (B,T,C=head_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed39b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.heads = nn.ModuleList([SelfAttentionHead() for i in range(n_heads)])\n",
    "        self.proj = nn.Linear(embed_dims, embed_dims, bias=False) # embed_dims = n_heads * head_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = torch.cat([attn_head(x) for attn_head in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a386dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82018dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention()\n",
    "        self.ln1 = nn.LayerNorm(embed_dims)\n",
    "        self.ln2 = nn.LayerNorm(embed_dims)\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dims, 4*embed_dims), # following attention-is-all-you-need paper for num hidden units\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*embed_dims, embed_dims),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Applies layernorm before self-attention.\n",
    "        # In the attention-is-all-you-need paper they apply it afterwards, \n",
    "        # but apparently pre-ln performs better. pre-ln paper: https://arxiv.org/pdf/2002.04745.pdf\n",
    "        \n",
    "        x = x + self.attn(self.ln1(x)) # (B,embed_dims)\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66653e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embed_dims)\n",
    "        \n",
    "        # positional encoding\n",
    "        self.pos_embedding_table = nn.Embedding(block_size, embed_dims)\n",
    "        \n",
    "        # transformer layers\n",
    "        # self.multihead_attn1 = MultiHeadAttention()\n",
    "        # self.block1 = Block()\n",
    "        self.blocks = nn.Sequential(*[Block() for i in range(n_layers)])\n",
    "        \n",
    "        # output layers\n",
    "        self.lm_head = nn.Linear(embed_dims, vocab_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, context, targets=None):\n",
    "        \n",
    "        B, T = context.shape\n",
    "        \n",
    "        # get the embedding vectors word-to-vec style\n",
    "        token_emb = self.token_embedding_table(context) # (Batch, Time, Channels) ==> [4, 8, 62]\n",
    "        \n",
    "        # add the positional embedding'\n",
    "        pos_emb = self.pos_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        \n",
    "        x = token_emb + pos_emb\n",
    "\n",
    "        # transformer forward pass\n",
    "        x = self.blocks(x)\n",
    "\n",
    "        # output layers\n",
    "        logits = self.lm_head(x)        \n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C) # [32,64]\n",
    "            targets = targets.view(B*T) # [32]\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, context, max_new_tokens):\n",
    "        \n",
    "        \n",
    "        # context: (Batch, Time) ==> [4, 8]\n",
    "        # -> extend context in Time dimension for max_new_tokens\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            \n",
    "            # get prediction\n",
    "            # logits, loss = self(xb, yb)\n",
    "            print(context.shape)\n",
    "            logits = self(context)\n",
    "            \n",
    "            # get logits for the last character \n",
    "            # (because we only need the last char to predict with our bigram model)\n",
    "            logits = logits.view(batch_size,-1,vocab_size) # (B,T,C)\n",
    "            logits = logits[:, -1, :] # (B,C) for only the last character\n",
    "            \n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            next_token = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            \n",
    "            # append next token to the sequence\n",
    "            context = torch.cat((context, next_token), dim=1) # (B,T+1)\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def generate_to_text(self, context, max_new_tokens):\n",
    "        context = self.generate(context, max_new_tokens)\n",
    "        return decode(context[0].tolist())\n",
    "\n",
    "model = TransformerLanguageModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51391e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) # 3e-4\n",
    "\n",
    "for step in tqdm(range(training_steps)):\n",
    "    \n",
    "    # get a batch\n",
    "    xb, yb = get_batch(train_data)\n",
    "    \n",
    "    # predict and get loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b5e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a8c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(losses[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01380e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "zero_context = torch.zeros((batch_size,1), device=device)\n",
    "xb, yb = get_batch(train_data)\n",
    "model.generate_to_text(xb, max_new_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, prompt=None, max_new_tokens=200):\n",
    "    if prompt is None:\n",
    "        # give zero context\n",
    "        prompt_tensor = torch.zeros((batch_size,1), device=device)\n",
    "    else:\n",
    "        # convert prompt to a batched tensor\n",
    "        prompt_tensor = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
    "        prompt_tensor = prompt_tensor.repeat(batch_size,1)\n",
    "    output = model.generate_to_text(prompt_tensor, max_new_tokens)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc6f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Lex, do you think the \"\n",
    "generate_response(model, prompt, max_new_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48542a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"5M_1k_steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = TransformerLanguageModel().to(device)\n",
    "model2.load_state_dict(torch.load(\"5M_1k_steps\"))\n",
    "model2.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab536fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Lex, do you think the \"\n",
    "generate_response(model2, prompt, max_new_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7a430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
