{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c6f554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello worldo!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello worldo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa94449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2f3c0cd530>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(35897932)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e1971",
   "metadata": {},
   "source": [
    "### Get text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e97ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text_corpus.txt\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()[:10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6ff1d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '%', \"'\", ',', '.', '0', '1', '2', '3', '5', '6', '7', '8', '9', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea75fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f90281",
   "metadata": {},
   "source": [
    "### Encode the characters to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f56c27f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder and decoder dicts\n",
    "\n",
    "char_int_mapping = dict()\n",
    "int_char_mapping = dict()\n",
    "\n",
    "for i, c in enumerate(sorted(set(text))):\n",
    "    char_int_mapping[c] = i\n",
    "    int_char_mapping[i] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f799812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "g\n"
     ]
    }
   ],
   "source": [
    "# examples\n",
    "print(char_int_mapping[\"g\"])\n",
    "print(int_char_mapping[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56852e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(string: str) -> List[int]:\n",
    "    int_list = [char_int_mapping[char] for char in string]\n",
    "    return int_list\n",
    "\n",
    "def decode(int_list: List[int]) -> str:\n",
    "    string = [int_char_mapping[num] for num in int_list]\n",
    "    return \"\".join(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a77fe53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 40, 47, 47, 50, 50, 50]\n",
      "hellooo\n"
     ]
    }
   ],
   "source": [
    "# examples\n",
    "print(encode(\"hellooo\"))\n",
    "print(decode([43, 40, 47, 47, 50, 50, 50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "931bc151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43, 40, 47, 47, 50, 1, 58, 50, 53, 47, 39]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b0040",
   "metadata": {},
   "source": [
    "### Make it a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d7650c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.int32)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222f0765",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49865796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ffb6c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 1000\n"
     ]
    }
   ],
   "source": [
    "N = int(0.9*len(data))\n",
    "train_data = data[:N]\n",
    "test_data = data[N:]\n",
    "\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f353e",
   "metadata": {},
   "source": [
    "### Create minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff15c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8 # block_size is the maximum context length (input textblock size)\n",
    "minibatch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a74fc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 53, 40, 48, 40, 48, 37, 40], dtype=torch.int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:block_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "032acc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(split: torch.tensor):\n",
    "    offsets = np.random.randint(0, len(split) - minibatch_size, size=minibatch_size)\n",
    "    x = torch.stack([split[i:i+block_size] for i in offsets])\n",
    "    y = torch.stack([split[i+1:i+block_size+1] for i in offsets])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16b37b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[44, 50, 49,  1, 36, 49, 39,  1],\n",
       "        [44, 49, 42,  0,  1, 36,  1, 46],\n",
       "        [40, 40, 39,  1, 50, 41,  1, 54],\n",
       "        [40, 49,  0,  1, 36,  1, 38, 43]], dtype=torch.int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_minibatch(train_data)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4dc59eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50, 49,  1, 36, 49, 39,  1, 43],\n",
       "        [49, 42,  0,  1, 36,  1, 46, 49],\n",
       "        [40, 39,  1, 50, 41,  1, 54, 50],\n",
       "        [49,  0,  1, 36,  1, 38, 43, 36]], dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1859006f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en\\n a ch'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(x[3].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6caf66d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- BATCH 0 -----\n",
      "context: i -> target: o\n",
      "context: io -> target: n\n",
      "context: ion -> target:  \n",
      "context: ion  -> target: a\n",
      "context: ion a -> target: n\n",
      "context: ion an -> target: d\n",
      "context: ion and -> target:  \n",
      "context: ion and  -> target: h\n",
      "\n",
      "context: [44] -> target: 50\n",
      "context: [44, 50] -> target: 49\n",
      "context: [44, 50, 49] -> target: 1\n",
      "context: [44, 50, 49, 1] -> target: 36\n",
      "context: [44, 50, 49, 1, 36] -> target: 49\n",
      "context: [44, 50, 49, 1, 36, 49] -> target: 39\n",
      "context: [44, 50, 49, 1, 36, 49, 39] -> target: 1\n",
      "context: [44, 50, 49, 1, 36, 49, 39, 1] -> target: 43\n",
      "\n",
      "----- BATCH 1 -----\n",
      "context: i -> target: n\n",
      "context: in -> target: g\n",
      "context: ing -> target: \n",
      "\n",
      "context: ing\n",
      " -> target:  \n",
      "context: ing\n",
      "  -> target: a\n",
      "context: ing\n",
      " a -> target:  \n",
      "context: ing\n",
      " a  -> target: k\n",
      "context: ing\n",
      " a k -> target: n\n",
      "\n",
      "context: [44] -> target: 49\n",
      "context: [44, 49] -> target: 42\n",
      "context: [44, 49, 42] -> target: 0\n",
      "context: [44, 49, 42, 0] -> target: 1\n",
      "context: [44, 49, 42, 0, 1] -> target: 36\n",
      "context: [44, 49, 42, 0, 1, 36] -> target: 1\n",
      "context: [44, 49, 42, 0, 1, 36, 1] -> target: 46\n",
      "context: [44, 49, 42, 0, 1, 36, 1, 46] -> target: 49\n",
      "\n",
      "----- BATCH 2 -----\n",
      "context: e -> target: e\n",
      "context: ee -> target: d\n",
      "context: eed -> target:  \n",
      "context: eed  -> target: o\n",
      "context: eed o -> target: f\n",
      "context: eed of -> target:  \n",
      "context: eed of  -> target: s\n",
      "context: eed of s -> target: o\n",
      "\n",
      "context: [40] -> target: 40\n",
      "context: [40, 40] -> target: 39\n",
      "context: [40, 40, 39] -> target: 1\n",
      "context: [40, 40, 39, 1] -> target: 50\n",
      "context: [40, 40, 39, 1, 50] -> target: 41\n",
      "context: [40, 40, 39, 1, 50, 41] -> target: 1\n",
      "context: [40, 40, 39, 1, 50, 41, 1] -> target: 54\n",
      "context: [40, 40, 39, 1, 50, 41, 1, 54] -> target: 50\n",
      "\n",
      "----- BATCH 3 -----\n",
      "context: e -> target: n\n",
      "context: en -> target: \n",
      "\n",
      "context: en\n",
      " -> target:  \n",
      "context: en\n",
      "  -> target: a\n",
      "context: en\n",
      " a -> target:  \n",
      "context: en\n",
      " a  -> target: c\n",
      "context: en\n",
      " a c -> target: h\n",
      "context: en\n",
      " a ch -> target: a\n",
      "\n",
      "context: [40] -> target: 49\n",
      "context: [40, 49] -> target: 0\n",
      "context: [40, 49, 0] -> target: 1\n",
      "context: [40, 49, 0, 1] -> target: 36\n",
      "context: [40, 49, 0, 1, 36] -> target: 1\n",
      "context: [40, 49, 0, 1, 36, 1] -> target: 38\n",
      "context: [40, 49, 0, 1, 36, 1, 38] -> target: 43\n",
      "context: [40, 49, 0, 1, 36, 1, 38, 43] -> target: 36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in range(minibatch_size):\n",
    "    print(f\"----- BATCH {b} -----\")\n",
    "    \n",
    "    for t in range(block_size):\n",
    "        context = x[b][:t+1]\n",
    "        target = y[b][t]\n",
    "        print(f\"context: {decode(context.tolist())} -> target: {decode([int(target)])}\")\n",
    "    print()\n",
    "        \n",
    "    for t in range(block_size):\n",
    "        context = x[b][:t+1]\n",
    "        target = y[b][t]\n",
    "        print(f\"context: {context.tolist()} -> target: {int(target)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e228c",
   "metadata": {},
   "source": [
    "### Create a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83559181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets):\n",
    "        logits = self.token_embedding_table(idx) # gets one embedding table row with probs for each next char\n",
    "        char_probs = F.softmax(logits, dim=-1)\n",
    "        preds = torch.argmax(char_probs, dim=-1)\n",
    "        loss = F.cross_entropy(preds, targets)\n",
    "        return preds, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49bd3544",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected floating point type for target with class probabilities, got Int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m mini_model \u001b[38;5;241m=\u001b[39m BigramLanguageModel(vocab_size)\n\u001b[1;32m      3\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m get_minibatch(train_data)\n\u001b[0;32m----> 4\u001b[0m out, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmini_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mBigramLanguageModel.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m      9\u001b[0m char_probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(char_probs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m preds, loss\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3013\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Int"
     ]
    }
   ],
   "source": [
    "mini_model = BigramLanguageModel(vocab_size)\n",
    "\n",
    "xb, yb = get_minibatch(train_data)\n",
    "out, loss = mini_model(xb, yb)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = F.softmax(out, dim=-1) # logits\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3664d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(a, dim=-1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa9b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1636465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
