{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa94449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa39e7f7150>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(3654)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b20532c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e1c6932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# report the parameters | and loss with 5k training steps:\n",
    "\n",
    "# --- small 10k dataset ---\n",
    "# bigram model: 3844 ==> loss to 2.5\n",
    "# with one multihead attention (5 heads): 53262 ==> loss to 0.35\n",
    "# with one multihead attention (5 heads) and residual connection: 53262 ==> loss to 0.30\n",
    "# with one full block: 134162 ==> loss to 0.24\n",
    "# with 5 blocks: 617762 ==> loss to 0.12\n",
    "\n",
    "# --- large dataset --- \n",
    "# bigger model: 5015318 (5M) ==> loss to 0.0116"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e1971",
   "metadata": {},
   "source": [
    "### Get text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e97ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text_corpus.txt\", encoding=\"utf-8\") as f:\n",
    "    text = f.read() # [:10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f718ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38739496"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6ff1d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '$', '%', '&', \"'\", '+', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '´', 'É', 'Ö', 'Ü', 'á', 'ã', 'å', 'ç', 'è', 'é', 'ê', 'í', 'ó', 'ô', 'ö', 'ø', 'ù', 'ü', 'ć', 'ł', 'ő', 'Б', 'В', 'Г', 'Д', 'К', 'Н', 'П', 'Р', 'С', 'Т', 'У', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', '–', '—', '…', '가', '들', '어']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ea75fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f90281",
   "metadata": {},
   "source": [
    "### Encode the characters to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f56c27f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder and decoder dicts\n",
    "\n",
    "char_int_mapping = dict()\n",
    "int_char_mapping = dict()\n",
    "\n",
    "for i, c in enumerate(sorted(set(text))):\n",
    "    char_int_mapping[c] = i\n",
    "    int_char_mapping[i] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56852e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(string: str) -> List[int]:\n",
    "    int_list = [char_int_mapping[char] for char in string]\n",
    "    return int_list\n",
    "\n",
    "def decode(int_list: List[int]) -> str:\n",
    "    string = [int_char_mapping[num] for num in int_list]\n",
    "    return \"\".join(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b0040",
   "metadata": {},
   "source": [
    "### Make it a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d7650c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([38739496])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222f0765",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ffb6c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34865546 3873950\n"
     ]
    }
   ],
   "source": [
    "N = int(0.9*len(data))\n",
    "train_data = data[:N]\n",
    "test_data = data[N:]\n",
    "\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f353e",
   "metadata": {},
   "source": [
    "### Create minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff15c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8 # block_size is the maximum context length (input textblock size)\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "032acc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split: torch.tensor):\n",
    "    offsets = np.random.randint(0, len(split) - block_size, size=batch_size)\n",
    "    x = torch.stack([split[i:i+block_size] for i in offsets]).to(device)\n",
    "    y = torch.stack([split[i+1:i+block_size+1] for i in offsets]).to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c4b72",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ffa661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "training_steps = 15000\n",
    "embed_dims = 256 # is equivalent to d_model\n",
    "block_size = 256\n",
    "batch_size = 64\n",
    "n_heads = 8\n",
    "head_size = embed_dims // n_heads\n",
    "n_layers = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0ca7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionHead(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.proj_q = nn.Linear(embed_dims, head_size, bias=False)\n",
    "        self.proj_k = nn.Linear(embed_dims, head_size, bias=False)\n",
    "        self.proj_v = nn.Linear(embed_dims, head_size, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" \n",
    "        Applies masked scaled dot-product attention\n",
    "        between vectors of queries Q, keys K and values V. \n",
    "        \"\"\"\n",
    "        B,T,C = x.shape\n",
    "        \n",
    "        Q = self.proj_q(x)\n",
    "        K = self.proj_k(x)\n",
    "        V = self.proj_v(x)\n",
    "\n",
    "        W = (Q @ K.transpose(-1,-2)) # (B, T, C) @ (B, C, T) ==> (B,T,T)\n",
    "        W /= torch.sqrt(torch.tensor(head_size))\n",
    "        \n",
    "        # mask out forbidden connections\n",
    "        tril = torch.tril(torch.ones((block_size, block_size), device=device))\n",
    "        W = W.masked_fill(tril[:T, :T]==0, float(\"-inf\")) # make smaller so it fits if context < block_size\n",
    "        W = F.softmax(W, dim=1)\n",
    "        out = W @ V\n",
    "        return out # (B,T,C=head_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f44fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.heads = nn.ModuleList([SelfAttentionHead() for i in range(n_heads)])\n",
    "        self.proj = nn.Linear(embed_dims, embed_dims, bias=False) # embed_dims = n_heads * head_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = torch.cat([attn_head(x) for attn_head in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74f2907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention()\n",
    "        self.ln1 = nn.LayerNorm(embed_dims)\n",
    "        self.ln2 = nn.LayerNorm(embed_dims)\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dims, 4*embed_dims), # following attention-is-all-you-need paper for num hidden units\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*embed_dims, embed_dims),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Applies layernorm before self-attention.\n",
    "        # In the attention-is-all-you-need paper they apply it afterwards, \n",
    "        # but apparently pre-ln performs better. pre-ln paper: https://arxiv.org/pdf/2002.04745.pdf\n",
    "        \n",
    "        x = x + self.attn(self.ln1(x)) # (B,embed_dims)\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fddc8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embed_dims)\n",
    "        \n",
    "        # positional encoding\n",
    "        self.pos_embedding_table = nn.Embedding(block_size, embed_dims)\n",
    "        \n",
    "        # transformer layers\n",
    "        # self.multihead_attn1 = MultiHeadAttention()\n",
    "        # self.block1 = Block()\n",
    "        self.blocks = nn.Sequential(*[Block() for i in range(n_layers)])\n",
    "        \n",
    "        # output layers\n",
    "        self.lm_head = nn.Linear(embed_dims, vocab_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, context, targets=None):\n",
    "        \n",
    "        B, T = context.shape\n",
    "        \n",
    "        # get the embedding vectors word-to-vec style\n",
    "        token_emb = self.token_embedding_table(context) # (Batch, Time, Channels) ==> [4, 8, 62]\n",
    "        \n",
    "        # add the positional embedding'\n",
    "        pos_emb = self.pos_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        \n",
    "        x = token_emb + pos_emb\n",
    "\n",
    "        # transformer forward pass\n",
    "        x = self.blocks(x)\n",
    "\n",
    "        # output layers\n",
    "        logits = self.lm_head(x)        \n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C) # [32,64]\n",
    "            targets = targets.view(B*T) # [32]\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, context, max_new_tokens):\n",
    "        B, T = context.shape\n",
    "        \n",
    "        # context: (Batch, Time) ==> [4, 8]\n",
    "        # -> extend context in Time dimension for max_new_tokens\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            \n",
    "            # get prediction\n",
    "            # logits, loss = self(xb, yb)\n",
    "            logits, loss = self(context[:,-block_size:])\n",
    "            \n",
    "            # get logits for the last character (for the next token)\n",
    "            logits = logits.view(B,-1,vocab_size) # (B,T,C)\n",
    "            logits = logits[:, -1, :] # (B,C) for only the last character\n",
    "            \n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            next_token = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            \n",
    "            # append next token to the sequence\n",
    "            context = torch.cat((context, next_token), dim=1) # (B,T+1)\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def generate_to_text(self, context, max_new_tokens):\n",
    "        context = self.generate(context, max_new_tokens)\n",
    "        return decode(context[0].tolist())\n",
    "\n",
    "model = TransformerLanguageModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "874b1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    losses = []\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "    \n",
    "    for step in tqdm(range(training_steps)):\n",
    "        \n",
    "        # get a batch\n",
    "        xb, yb = get_batch(train_data)\n",
    "        \n",
    "        # predict and get loss\n",
    "        logits, loss = model(xb, yb)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "        if step % 500 == 0 or step == training_steps-1:\n",
    "            if not os.path.exists(\"weights\"):\n",
    "                os.mkdir(\"weights\")\n",
    "            torch.save({\n",
    "                    'epoch': step,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    }, f\"weights/{loss.item():5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54b99d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                    | 103/15000 [00:43<1:41:46,  2.44it/s]"
     ]
    }
   ],
   "source": [
    "train()\n",
    "\n",
    "# plt.plot(losses)\n",
    "# np.mean(losses[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba44a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "# zero_context = torch.zeros((batch_size,1), device=device)\n",
    "# xb, yb = get_batch(train_data)\n",
    "# model.generate_to_text(xb, max_new_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7acec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TransformerLanguageModel().to(device)\n",
    "#model.load_state_dict(torch.load(\"5M_1k_steps\"))\n",
    "#model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6001677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_model(model, prompt=None, max_new_tokens=200):\n",
    "    if prompt is None or prompt == \"\":\n",
    "        # give zero context\n",
    "        prompt_tensor = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "    else:\n",
    "        # convert prompt to a batched tensor\n",
    "        prompt_tensor = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
    "        prompt_tensor = torch.unsqueeze(prompt_tensor, 0)\n",
    "    output = model.generate_to_text(prompt_tensor, max_new_tokens)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ce93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Lex, think theLex, do you think theLex, do you think theLex, do you think theLex, do you think theLex, do you think theLex, do you think theLex, do you think the\"\n",
    "print(len(prompt))\n",
    "prompt_model(model, prompt, max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bfdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_tensor = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
    "# prompt_tensor = torch.unsqueeze(prompt_tensor, 0)\n",
    "# output = model.generate_to_text(prompt_tensor, 20)\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8a1793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_tensor = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "# output = model.generate_to_text(prompt_tensor, 20)\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8c691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
